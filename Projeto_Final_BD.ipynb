{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5JWGDg1Tt6s",
    "tags": []
   },
   "source": [
    "<text> INSPER - Big Data e Computação em Nuvem <text>\n",
    "    \n",
    "<text> Grupo 1: André Gambry, Mainara Cardoso, Tiago Pardo <text>\n",
    "\n",
    "# Big Data e Computação em Nuvem - Projeto Final\n",
    "\n",
    "## Objetivo do projeto: Previsão de cancelamento de vôos por condições meteorológicas\n",
    "    \n",
    "## Dados: \n",
    "    Airline Delay: https://www.kaggle.com/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018\n",
    "    Airports.csv: https://github.com/PacktPublishing/Pandas-Cookbook/blob/master/data/descriptions/airports.csv?plain=1\n",
    "    Weather: https://github.com/adambry/Projeto_Final_BigData/blob/main/df_weather.csv\n",
    "    \n",
    "Obs: Os dados de Weather foram obtidos via Web Scrapping do site: https://www.ncei.noaa.gov/\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ_ky0q2Tt6z"
   },
   "source": [
    "# 1. BIBLIOTECAS, SESSÃO SPARK E IMPORTAÇÃO DE DADOS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, col, expr, year, month, date_format, when, countDistinct, trim, lower\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from io import StringIO\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sessão Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "            .builder\n",
    "            .master(\"local[4]\")\n",
    "            .appName(\"Projeto Final\")\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.4,com.microsoft.azure:azure-storage:8.6.6\")\n",
    "            .config(\"spark.driver.memory\", \"4g\")\n",
    "            .config(\"spark.executor.memory\", \"5g\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "#sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3 Importação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3.1. Base \"airline delay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BtlPQBMUev9f"
   },
   "outputs": [],
   "source": [
    "STORAGE_ACCOUNT = 'dlspadseastusprod'\n",
    "CONTAINER = 'big-data-comp-nuvem'\n",
    "FOLDER = 'airline-delay'\n",
    "TOKEN = 'lSuH4ZI9BhOFEhCF/7ZQbrpPBIhgtLcPDfXjJ8lMxQZjaADW4p6tcmiZGDX9u05o7FqSE2t9d2RD+ASt0YFG8g=='\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.key.\" + STORAGE_ACCOUNT + \".blob.core.windows.net\", TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \n",
    "    No snipet abaixo estamos importanto dados apenas para o arquivo do ano de 2011. Ajustar para importar dos demais anos\n",
    "    <font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pfBLgWVPk1Xe",
    "outputId": "ea7abda6-e0df-4f07-fe30-6cef0b26e389"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4529</td>\n",
       "      <td>BOS</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1830</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4532</td>\n",
       "      <td>BNA</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1100</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4532</td>\n",
       "      <td>DCA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1400</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4537</td>\n",
       "      <td>RDU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1710</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4540</td>\n",
       "      <td>CMH</td>\n",
       "      <td>LGA</td>\n",
       "      <td>1340</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0 2011-01-01         MQ               4529    BOS  JFK          1830   \n",
       "1 2011-01-01         MQ               4532    BNA  DCA          1100   \n",
       "2 2011-01-01         MQ               4532    DCA  JFK          1400   \n",
       "3 2011-01-01         MQ               4537    RDU  JFK          1710   \n",
       "4 2011-01-01         MQ               4540    CMH  LGA          1340   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  CRS_ELAPSED_TIME  \\\n",
       "0    1823.0       -7.0      68.0      1931.0  ...              90.0   \n",
       "1    1052.0       -8.0      11.0      1103.0  ...              95.0   \n",
       "2    1358.0       -2.0       9.0      1407.0  ...              79.0   \n",
       "3    1706.0       -4.0      59.0      1805.0  ...             105.0   \n",
       "4    1340.0        0.0      14.0      1354.0  ...             105.0   \n",
       "\n",
       "   ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
       "0                146.0      48.0     187.0            0.0            0.0   \n",
       "1                 88.0      74.0     562.0            NaN            NaN   \n",
       "2                 73.0      60.0     213.0            NaN            NaN   \n",
       "3                159.0      85.0     426.0            0.0            0.0   \n",
       "4                 95.0      77.0     478.0            NaN            NaN   \n",
       "\n",
       "  NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 27  \n",
       "0      49.0             0.0                  0.0         None  \n",
       "1       NaN             NaN                  NaN         None  \n",
       "2       NaN             NaN                  NaN         None  \n",
       "3      50.0             0.0                  0.0         None  \n",
       "4       NaN             NaN                  NaN         None  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "config.set(\"fs.azure.account.key.\" + STORAGE_ACCOUNT + \".blob.core.windows.net\", TOKEN)\n",
    "\n",
    "df_airline_delay = spark.read.csv(\"wasbs://{}@{}.blob.core.windows.net/{}/2011.csv\".format(CONTAINER, STORAGE_ACCOUNT, FOLDER), header=True, inferSchema=True)\n",
    "\n",
    "df_airline_delay.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3.2. Base \"weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>tavg</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>December</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>50.4</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>67.4</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>September</td>\n",
       "      <td>79.4</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>August</td>\n",
       "      <td>79.5</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Year      Month  tavg   pcp\n",
       "0  Alabama  2018   December  49.0  9.95\n",
       "1  Alabama  2018   November  50.4  6.29\n",
       "2  Alabama  2018    October  67.4  2.69\n",
       "3  Alabama  2018  September  79.4  6.21\n",
       "4  Alabama  2018     August  79.5  5.03"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL do arquivo no GitHub\n",
    "url = \"https://github.com/adambry/Projeto_Final_BigData/raw/main/df_weather.csv\"\n",
    "\n",
    "df_weather = pd.read_csv(url)\n",
    "\n",
    "df_weather = spark.createDataFrame(df_weather)\n",
    "\n",
    "df_weather.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando ocorrência de duplicadas na base\n",
    "df_weather_duplicadas = df_weather.groupBy(\"State\", \"Year\",\"Month\", \"tavg\", \"pcp\").count().filter(col(\"count\") > 1)\n",
    "\n",
    "df_weather_duplicadas.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriricamos que a importação dos dados via o WebScrapping duplicou cada valor na base. Portanto, removeremos as duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = df_weather.dropDuplicates()\n",
    "\n",
    "df_weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrando dados do ano de 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State     49\n",
       "Year       1\n",
       "Month     12\n",
       "tavg     394\n",
       "pcp      391\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = df_weather.filter(col(\"Year\") == 2011)\n",
    "\n",
    "df_weather.toPandas().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. Base \"airports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>iata_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>OCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>PQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>CO</td>\n",
       "      <td>CSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>JCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nunapitchuk Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>NUP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                     name iso_country iso_region iata_code\n",
       "0  small_airport  Ocean Reef Club Airport          US         FL       OCA\n",
       "1  small_airport    Pilot Station Airport          US         AK       PQS\n",
       "2  small_airport    Crested Butte Airpark          US         CO       CSE\n",
       "3  small_airport        LBJ Ranch Airport          US         TX       JCY\n",
       "4  small_airport      Nunapitchuk Airport          US         AK       NUP"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/adambry/Projeto_Final_BigData/main/Aeroportos_US.csv'\n",
    "\n",
    "# Especifique as colunas de interesse\n",
    "df_airports_region = pd.read_csv(url, delimiter=';')\n",
    "\n",
    "df_airports_region = spark.createDataFrame(df_airports_region)\n",
    "\n",
    "df_airports_region.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TRATAMENTO NOS DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Limpeza Aeroportos fora dos EUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudo da base para verificar se os estados registrados na coluna STATE na base df_airports_region estão corretos\n",
    "df_airports_region.select(\"iso_region\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que os Estados Unidos possuem 50 estados. Poranto, precisamos vamos identificar os excedentes e retirá-los da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|iso_region|\n",
      "+----------+\n",
      "|        DC|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identificando Estados Excedentes\n",
    "\n",
    "# Lista de estados dos EUA (https://pt.wikipedia.org/wiki/Estados_dos_Estados_Unidos)\n",
    "us_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Filtra os estados excedentes\n",
    "excess_states = df_airports_region.select(\"iso_region\").distinct().filter(~col(\"iso_region\").isin(us_states))\n",
    "\n",
    "# Exibe os estados excedentes\n",
    "excess_states.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verificando quais aeroportos estão nos Estados não identificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------------------------------+-----------+----------+---------+\n",
      "|type         |name                                     |iso_country|iso_region|iata_code|\n",
      "+-------------+-----------------------------------------+-----------+----------+---------+\n",
      "|large_airport|Ronald Reagan Washington National Airport|US         |DC        |DCA      |\n",
      "+-------------+-----------------------------------------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtra os aeroportos com base nos estados excedentes\n",
    "df_excess_airports = df_airports_region.filter(col(\"iso_region\").isin([row.iso_region for row in excess_states.collect()]))\n",
    "\n",
    "# Exibe os aeroportos nos estados excedentes\n",
    "df_excess_airports.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de consultas na internet, verificamos que este aeroporto fica em Washginton. Portanto, a iso_region deve ser alterado para WA, sigla do Estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substitui o valor \"DC\" por \"WA\" na coluna \"iso_region\"\n",
    "df_airports_region = df_airports_region.withColumn(\"iso_region\", when(col(\"iso_region\") == \"DC\", \"WA\").otherwise(col(\"iso_region\")))\n",
    "\n",
    "# Exibe os aeroportos após a substituição\n",
    "df_airports_region.select(\"iso_region\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Transformação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Tabela df_airports_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformação da sigla dos estados para o nome por extenso para corresponder aos valores da tabela df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>STATE_FULL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>OCA</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>PQS</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>CO</td>\n",
       "      <td>CSE</td>\n",
       "      <td>Colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>JCY</td>\n",
       "      <td>Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nunapitchuk Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>NUP</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                     name iso_country iso_region iata_code  \\\n",
       "0  small_airport  Ocean Reef Club Airport          US         FL       OCA   \n",
       "1  small_airport    Pilot Station Airport          US         AK       PQS   \n",
       "2  small_airport    Crested Butte Airpark          US         CO       CSE   \n",
       "3  small_airport        LBJ Ranch Airport          US         TX       JCY   \n",
       "4  small_airport      Nunapitchuk Airport          US         AK       NUP   \n",
       "\n",
       "  STATE_FULL_NAME  \n",
       "0         Florida  \n",
       "1          Alaska  \n",
       "2        Colorado  \n",
       "3           Texas  \n",
       "4          Alaska  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_full_name = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# Criar a nova coluna com nomes de estados por extenso\n",
    "df_airports_region = df_airports_region.withColumn(\"STATE_FULL_NAME\", col(\"iso_region\").cast(\"string\")).replace(state_full_name, subset=\"STATE_FULL_NAME\")\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_airports_region.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retiraremos todos os espaços antes e depois das strings que utilizaremos para join e as deixaremos em snakecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>STATE_FULL_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>oca</td>\n",
       "      <td>florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>pqs</td>\n",
       "      <td>alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>CO</td>\n",
       "      <td>cse</td>\n",
       "      <td>colorado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>jcy</td>\n",
       "      <td>texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nunapitchuk Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>nup</td>\n",
       "      <td>alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                     name iso_country iso_region iata_code  \\\n",
       "0  small_airport  Ocean Reef Club Airport          US         FL       oca   \n",
       "1  small_airport    Pilot Station Airport          US         AK       pqs   \n",
       "2  small_airport    Crested Butte Airpark          US         CO       cse   \n",
       "3  small_airport        LBJ Ranch Airport          US         TX       jcy   \n",
       "4  small_airport      Nunapitchuk Airport          US         AK       nup   \n",
       "\n",
       "  STATE_FULL_NAME  \n",
       "0         florida  \n",
       "1          alaska  \n",
       "2        colorado  \n",
       "3           texas  \n",
       "4          alaska  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airports_region = df_airports_region.withColumn(\"STATE_FULL_NAME\", trim(\"STATE_FULL_NAME\"))\n",
    "df_airports_region = df_airports_region.withColumn(\"STATE_FULL_NAME\", lower(\"STATE_FULL_NAME\"))\n",
    "df_airports_region = df_airports_region.withColumn(\"iata_code\", trim(\"iata_code\"))\n",
    "df_airports_region = df_airports_region.withColumn(\"iata_code\", lower(\"iata_code\"))\n",
    "df_airports_region.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Tabela airline_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Retiraremos todos os espaços antes e depois das strings que utilizaremos para join e as deixaremos em snakecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cmh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGIN\n",
       "0    bos\n",
       "1    bna\n",
       "2    dca\n",
       "3    rdu\n",
       "4    cmh"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline_delay = df_airline_delay.withColumn(\"ORIGIN\", trim(\"ORIGIN\"))\n",
    "df_airline_delay = df_airline_delay.withColumn(\"ORIGIN\", lower(\"ORIGIN\"))\n",
    "df_airline_delay.select(\"ORIGIN\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando colunas de ano e mês a partir da FL_DATE na tabela df_airline_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE  Year    Month\n",
       "0 2011-01-01  2011  January\n",
       "1 2011-01-01  2011  January\n",
       "2 2011-01-01  2011  January\n",
       "3 2011-01-01  2011  January\n",
       "4 2011-01-01  2011  January"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline_delay = df_airline_delay.withColumn(\"Year\", year(\"FL_DATE\")).withColumn(\"Month\", date_format(col(\"FL_DATE\"), \"MMMM\"))\n",
    "df_airline_delay.select(\"FL_DATE\",\"Year\", \"Month\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Tabela Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variável State para snakecase e retirada de eventuais espaços antes e/ou depois da string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>tavg</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>california</td>\n",
       "      <td>2011</td>\n",
       "      <td>August</td>\n",
       "      <td>75.2</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>illinois</td>\n",
       "      <td>2011</td>\n",
       "      <td>August</td>\n",
       "      <td>74.8</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arkansas</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>california</td>\n",
       "      <td>2011</td>\n",
       "      <td>February</td>\n",
       "      <td>43.4</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connecticut</td>\n",
       "      <td>2011</td>\n",
       "      <td>September</td>\n",
       "      <td>66.4</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         State  Year      Month  tavg   pcp\n",
       "0   california  2011     August  75.2  0.10\n",
       "1     illinois  2011     August  74.8  1.87\n",
       "2     arkansas  2011    January  37.6  1.60\n",
       "3   california  2011   February  43.4  3.34\n",
       "4  connecticut  2011  September  66.4  7.78"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = df_weather.withColumn(\"State\", trim(\"State\"))\n",
    "df_weather = df_weather.withColumn(\"State\", lower(\"State\"))\n",
    "df_weather.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l2b1lRnTt63",
    "tags": []
   },
   "source": [
    "## 3.. Join nas tabelas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Join nas tabelas df_airport_region e df_airline_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6038444"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline_delay_airports = df_airline_delay.join(df_airports_region, df_airline_delay.ORIGIN == df_airports_region.iata_code, \"inner\")\n",
    "\n",
    "df_airline_delay_airports.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Join nas tabelas df_airline_delay_airports e df_weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando dataframe que será utilizado no pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>STATE_FULL_NAME</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>tavg</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>OO</td>\n",
       "      <td>6486</td>\n",
       "      <td>mmh</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Mammoth Yosemite Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>mmh</td>\n",
       "      <td>california</td>\n",
       "      <td>california</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "      <td>45.2</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>286</td>\n",
       "      <td>isp</td>\n",
       "      <td>BWI</td>\n",
       "      <td>945</td>\n",
       "      <td>945.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Long Island Mac Arthur Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>isp</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>1833</td>\n",
       "      <td>isp</td>\n",
       "      <td>BWI</td>\n",
       "      <td>820</td>\n",
       "      <td>826.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Long Island Mac Arthur Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>isp</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>1988</td>\n",
       "      <td>isp</td>\n",
       "      <td>BWI</td>\n",
       "      <td>1205</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Long Island Mac Arthur Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>isp</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>1990</td>\n",
       "      <td>isp</td>\n",
       "      <td>BWI</td>\n",
       "      <td>1545</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Long Island Mac Arthur Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>NY</td>\n",
       "      <td>isp</td>\n",
       "      <td>new york</td>\n",
       "      <td>new york</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0 2011-01-01         OO               6486    mmh  SFO          1736   \n",
       "1 2011-01-01         WN                286    isp  BWI           945   \n",
       "2 2011-01-01         WN               1833    isp  BWI           820   \n",
       "3 2011-01-01         WN               1988    isp  BWI          1205   \n",
       "4 2011-01-01         WN               1990    isp  BWI          1545   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  \\\n",
       "0       NaN        NaN       NaN         NaN  ...   \n",
       "1     945.0        0.0       9.0       954.0  ...   \n",
       "2     826.0        6.0       6.0       832.0  ...   \n",
       "3    1303.0       58.0       8.0      1311.0  ...   \n",
       "4    1546.0        1.0       7.0      1553.0  ...   \n",
       "\n",
       "                             name  iso_country  iso_region  iata_code  \\\n",
       "0        Mammoth Yosemite Airport           US          CA        mmh   \n",
       "1  Long Island Mac Arthur Airport           US          NY        isp   \n",
       "2  Long Island Mac Arthur Airport           US          NY        isp   \n",
       "3  Long Island Mac Arthur Airport           US          NY        isp   \n",
       "4  Long Island Mac Arthur Airport           US          NY        isp   \n",
       "\n",
       "   STATE_FULL_NAME       State  Year    Month  tavg   pcp  \n",
       "0       california  california  2011  January  45.2  1.28  \n",
       "1         new york    new york  2011  January  18.6  2.01  \n",
       "2         new york    new york  2011  January  18.6  2.01  \n",
       "3         new york    new york  2011  January  18.6  2.01  \n",
       "4         new york    new york  2011  January  18.6  2.01  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_airline_delay_airports.join(df_weather, (df_airline_delay_airports.STATE_FULL_NAME == df_weather.State) & (df_airline_delay_airports.Year == df_weather.Year) & (df_airline_delay_airports.Month == df_weather.Month), \"inner\")\n",
    "\n",
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se todos os valores corresponderam entre as duas tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_erro = df_airline_delay_airports.join(df_weather, (df_airline_delay_airports.STATE_FULL_NAME == df_weather.State) & (df_airline_delay_airports.Year == df_weather.Year) & (df_airline_delay_airports.Month == df_weather.Month), \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101304"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando falhas no Join\n",
    "\n",
    "unmatched_rows = df_erro.filter(col(\"State\").isNull())\n",
    "\n",
    "# Contagem das linhas não correspondidas\n",
    "unmatched_rows.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que a base possui mais de 6 milhões de registros, não aprofundaremos em entender as 101304 que não corresponderam entre as tabelas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = red> Retirar colunas que não fazem sentido do DF <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('WEATHER_DELAY_BIN', when(col('WEATHER_DELAY') == 0, 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Criação de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1.1 Cassificando atrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo variável com valor dos percentis 0.33 e 0.66 para posteriormente segmentar as distâncias.\n",
    "# documentação consultada: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.approxQuantile.html\n",
    "\n",
    "# percentis = df.stat.approxQuantile(\"DISTANCE\", [0.33, 0.66], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Foi necessário utilizar o recurso de format ao invés de utilizar diretamente a referência do objetos da variável percentis no corpo da expressão porque, de outra forma, o \\nPySpark interpretou percentis[0] e percentis[1] como literais de string, e não como valores da lista criada na variável percentis'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando coluna no dataframe para classificação das distâncias a partir dos percentis calculados\n",
    "# Foi utilizado o percentis[0] para acessar os valor do percentil 0.33 e percentis[1] para acessar o valor de percentis 0.66.\n",
    "''' Foi necessário utilizar o recurso de format ao invés de utilizar diretamente a referência do objetos da variável percentis no corpo da expressão porque, de outra forma, o \n",
    "PySpark interpretou percentis[0] e percentis[1] como literais de string, e não como valores da lista criada na variável percentis'''\n",
    "\n",
    "# df_classificacao_distancias = df.withColumn(\n",
    "#     'CLASSIFICACAO_DISTANCIAS',\n",
    "#     expr(\n",
    "#         \"CASE WHEN distance <= {} THEN 'proximos'\"\n",
    "#         \" WHEN distance <= {} THEN 'medio'\"\n",
    "#         \" ELSE 'distantes' END\".format(percentis[0], percentis[1])\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# df_classificacao_distancias.show(10)\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Análise Descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Análise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Variáveis numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> criar aqui gráficos para visualizarmos a dispersão dos dados em boxplot para as colunas numéricas pertinentes <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> criar aqui gráficos para visualizarmos a frequência das categorias para cada variável <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Criação de hipóteses\n",
    "\n",
    "<font color = red> criar aqui hipóteses subjetivas (de acordo com nossa interpretação subjetivas sobre os dados) de como as variáveis se comportam frente à variável resposta <font>\n",
    "    \n",
    "    Por exemplo: \n",
    "    1. Vôos entre aeroportos mais distantes tendem a ter mais atrasos por 'weather'\n",
    "    2. O número de vôos cancelados por motivos de 'weather' é maior em meses que possuem maior precipitação\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Análise Bivariada\n",
    "\n",
    "<font color=red> criar gráficos buscando responder as hipóteses criadas \n",
    "    <font>\n",
    "\n",
    "Isso é útil para criarmos uma intuição sobre a importância das variáveis nos modelos e obter maior autonomia para manipulação, evitando que nos tornemos totalmente dependente somente de algorítmos para seleção de variáveis, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Calculando % atraso em cada faixa\n",
    "\n",
    "<font color = red> necessita ajuste para pegar apenas vôos cancelados por motivo de 'weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencia_absoluta = df_classificacao_distancias.groupBy(\"CLASSIFICACAO_DISTANCIAS\").count()\n",
    "# total_atrasos = df_classificacao_distancias.count()\n",
    "\n",
    "# frequencia_absoluta.show()\n",
    "# total_atrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porcentagem_atrasos_por_classificacao_distancia = frequencia_absoluta.withColumn(\n",
    "#     \"PORCENTAGEM\",\n",
    "#     expr(\"count / {} * 100\".format(total_atrasos))\n",
    "# )\n",
    "\n",
    "# porcentagem_atrasos_por_classificacao_distancia.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2. Número de vôos diários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando gráfico com o número de vôos diários\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# ax = sns.lineplot(data=df_BOS_agrupado_data_pandas, x='FL_DATE', y='count')\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha='right')\n",
    "# ax.set(title='Número Diário de Voos',\n",
    "#        xlabel='Data',\n",
    "#        ylabel='Número de Voos')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2. Análise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= red> plotar aqui gráfico de correlação <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelagem de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ORIGIN', 'DEST', 'State', 'tavg', 'pcp', 'WEATHER_DELAY_BIN']\n",
    "df_ml = df.select(*cols)\n",
    "\n",
    "df_ml_sample = df_ml.sample(fraction=0.1, seed=3)\n",
    "\n",
    "cat_columns = ['ORIGIN', 'DEST', 'State']\n",
    "num_columns = ['tavg', 'pcp']\n",
    "\n",
    "index_output = [x+\"Index\" for x in cat_columns]\n",
    "ohe_output = [x+\"OHE\" for x in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=cat_columns,\n",
    "                             outputCols=index_output,\n",
    "                             handleInvalid=\"skip\")\n",
    "\n",
    "oheEncoder = OneHotEncoder(inputCols=index_output,\n",
    "                          outputCols=ohe_output)\n",
    "\n",
    "# Montar os recursos em um vetor\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs,\n",
    "                     outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "(train_data, test_data) = df_ml_sample.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Criar instâncias dos modelos de Regressão Logística e Floresta Aleatória\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.9999999457990196\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='WEATHER_DELAY_BIN')\n",
    "pipeline_lr = Pipeline(stages=[stringIndexer, oheEncoder, assembler, lr])\n",
    "\n",
    "model_lr = pipeline_lr.fit(train_data)\n",
    "\n",
    "predictions_lr = model_lr.transform(test_data)\n",
    "\n",
    "evaluator_lr = BinaryClassificationEvaluator(labelCol='WEATHER_DELAY_BIN')\n",
    "\n",
    "evaluation_lr = evaluator_lr.evaluate(predictions_lr)\n",
    "\n",
    "print(f'AUC:{evaluation_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.08993337109305\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol='features', labelCol='WEATHER_DELAY_BIN')\n",
    "pipeline_rf = Pipeline(stages=[stringIndexer, oheEncoder, assembler, rf])\n",
    "\n",
    "model_rf = pipeline_rf.fit(train_data)\n",
    "\n",
    "predictions_rf = model_rf.transform(test_data)\n",
    "\n",
    "evaluator_rf = RegressionEvaluator(labelCol=\"WEATHER_DELAY_BIN\", predictionCol=\"prediction\")\n",
    "\n",
    "evaluation_rf = evaluator_rf.evaluate(predictions_rf)\n",
    "\n",
    "print(f'RMSE:{evaluation_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Floresta aleatória com otimização de hiperparâmetros e validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "            .addGrid(rf.numTrees, [10, 100])\n",
    "            .build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m CrossValidator(\n\u001b[1;32m      2\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline_rf,\n\u001b[1;32m      3\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator_rf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m cvModel \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/ml/tuning.py:827\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    825\u001b[0m est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n\u001b[1;32m    826\u001b[0m epm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimatorParamMaps)\n\u001b[0;32m--> 827\u001b[0m numModels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m eva \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator)\n\u001b[1;32m    829\u001b[0m nFolds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumFolds)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'method' has no len()"
     ]
    }
   ],
   "source": [
    "cv = CrossValidator(\n",
    "    estimator=pipeline_rf,\n",
    "    evaluator=evaluator_rf,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    numFolds=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel = cv.fit(train_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
