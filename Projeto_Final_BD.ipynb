{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5JWGDg1Tt6s",
    "tags": []
   },
   "source": [
    "<text> INSPER - Big Data e Computação em Nuvem <text>\n",
    "    \n",
    "<text> Grupo 1: André Gambry, Mainara Cardoso, Tiago Pardo <text>\n",
    "\n",
    "# Big Data e Computação em Nuvem - Projeto Final\n",
    "\n",
    "## Objetivo do projeto: Previsão de cancelamento de vôos por condições meteorológicas\n",
    "    \n",
    "## Dados: \n",
    "    Airline Delay: https://www.kaggle.com/yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018\n",
    "    Airports.csv: https://github.com/PacktPublishing/Pandas-Cookbook/blob/master/data/descriptions/airports.csv?plain=1\n",
    "    Weather: https://github.com/adambry/Projeto_Final_BigData/blob/main/df_weather.csv\n",
    "    \n",
    "Obs: Os dados de Weather foram obtidos via Web Scrapping do site: https://www.ncei.noaa.gov/\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ_ky0q2Tt6z"
   },
   "source": [
    "# 1. BIBLIOTECAS, SESSÃO SPARK E IMPORTAÇÃO DE DADOS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, col, expr, year, month, date_format, when, countDistinct\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from io import StringIO\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sessão Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "            .builder\n",
    "            .master(\"local[4]\")\n",
    "            .appName(\"Projeto Final\")\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-azure:3.3.4,com.microsoft.azure:azure-storage:8.6.6\")\n",
    "            .config(\"spark.driver.memory\", \"4g\")\n",
    "            .config(\"spark.executor.memory\", \"5g\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.master', 'local[4]'),\n",
       " ('spark.jars.packages',\n",
       "  'org.apache.hadoop:hadoop-azure:3.3.4,com.microsoft.azure:azure-storage:8.6.6'),\n",
       " ('spark.driver.memory', '4g'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-storage-8.6.6.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/jovyan/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/jovyan/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.4.jar,file:///home/jovyan/.ivy2/jars/org.slf4j_slf4j-api-1.7.12.jar,file:///home/jovyan/.ivy2/jars/org.apache.commons_commons-lang3-3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.2.4.jar,file:///home/jovyan/.ivy2/jars/com.google.guava_guava-24.1.1-jre.jar,file:///home/jovyan/.ivy2/jars/com.google.code.findbugs_jsr305-1.3.9.jar,file:///home/jovyan/.ivy2/jars/org.checkerframework_checker-compat-qual-2.0.0.jar,file:///home/jovyan/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.1.3.jar,file:///home/jovyan/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.14.jar'),\n",
       " ('spark.app.name', 'Projeto Final'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.executor.memory', '5g'),\n",
       " ('spark.app.initial.file.urls',\n",
       "  'file:///home/jovyan/.ivy2/jars/org.checkerframework_checker-compat-qual-2.0.0.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/jovyan/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/jovyan/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.1.3.jar,file:///home/jovyan/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.4.jar,file:///home/jovyan/.ivy2/jars/org.apache.commons_commons-lang3-3.4.jar,file:///home/jovyan/.ivy2/jars/org.slf4j_slf4j-api-1.7.12.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/com.google.code.findbugs_jsr305-1.3.9.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-storage-8.6.6.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/com.google.guava_guava-24.1.1-jre.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.14.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.2.4.jar,file:///home/jovyan/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar'),\n",
       " ('spark.app.submitTime', '1701800657161'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/jovyan/BIG%20DATA%20E%20COMPUTAÇÃO%20EM%20NUVEM/Projeto%20Final/Projeto_Final_BigData/spark-warehouse'),\n",
       " ('spark.submit.pyFiles',\n",
       "  '/home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.4.jar,/home/jovyan/.ivy2/jars/com.microsoft.azure_azure-storage-8.6.6.jar,/home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,/home/jovyan/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,/home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.43.v20210629.jar,/home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,/home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,/home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,/home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,/home/jovyan/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,/home/jovyan/.ivy2/jars/commons-codec_commons-codec-1.15.jar,/home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.43.v20210629.jar,/home/jovyan/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.4.jar,/home/jovyan/.ivy2/jars/org.slf4j_slf4j-api-1.7.12.jar,/home/jovyan/.ivy2/jars/org.apache.commons_commons-lang3-3.4.jar,/home/jovyan/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.2.4.jar,/home/jovyan/.ivy2/jars/com.google.guava_guava-24.1.1-jre.jar,/home/jovyan/.ivy2/jars/com.google.code.findbugs_jsr305-1.3.9.jar,/home/jovyan/.ivy2/jars/org.checkerframework_checker-compat-qual-2.0.0.jar,/home/jovyan/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.1.3.jar,/home/jovyan/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,/home/jovyan/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.14.jar'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://jupyter-andregd1:35135/jars/commons-logging_commons-logging-1.1.3.jar,spark://jupyter-andregd1:35135/jars/org.eclipse.jetty_jetty-util-9.4.43.v20210629.jar,spark://jupyter-andregd1:35135/jars/org.slf4j_slf4j-api-1.7.12.jar,spark://jupyter-andregd1:35135/jars/com.google.errorprone_error_prone_annotations-2.1.3.jar,spark://jupyter-andregd1:35135/jars/com.fasterxml.jackson.core_jackson-core-2.9.4.jar,spark://jupyter-andregd1:35135/jars/com.microsoft.azure_azure-keyvault-core-1.2.4.jar,spark://jupyter-andregd1:35135/jars/com.google.guava_guava-24.1.1-jre.jar,spark://jupyter-andregd1:35135/jars/com.google.j2objc_j2objc-annotations-1.1.jar,spark://jupyter-andregd1:35135/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,spark://jupyter-andregd1:35135/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,spark://jupyter-andregd1:35135/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,spark://jupyter-andregd1:35135/jars/org.codehaus.mojo_animal-sniffer-annotations-1.14.jar,spark://jupyter-andregd1:35135/jars/com.microsoft.azure_azure-storage-8.6.6.jar,spark://jupyter-andregd1:35135/jars/org.eclipse.jetty_jetty-util-ajax-9.4.43.v20210629.jar,spark://jupyter-andregd1:35135/jars/com.google.code.findbugs_jsr305-1.3.9.jar,spark://jupyter-andregd1:35135/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,spark://jupyter-andregd1:35135/jars/commons-codec_commons-codec-1.15.jar,spark://jupyter-andregd1:35135/jars/org.apache.hadoop_hadoop-azure-3.3.4.jar,spark://jupyter-andregd1:35135/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,spark://jupyter-andregd1:35135/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,spark://jupyter-andregd1:35135/jars/org.apache.commons_commons-lang3-3.4.jar,spark://jupyter-andregd1:35135/jars/org.checkerframework_checker-compat-qual-2.0.0.jar'),\n",
       " ('spark.app.startTime', '1701800657499'),\n",
       " ('spark.driver.port', '35135'),\n",
       " ('spark.driver.host', 'jupyter-andregd1'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'local-1701800658368'),\n",
       " ('spark.files',\n",
       "  'file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-storage-8.6.6.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/jovyan/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/jovyan/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.4.jar,file:///home/jovyan/.ivy2/jars/org.slf4j_slf4j-api-1.7.12.jar,file:///home/jovyan/.ivy2/jars/org.apache.commons_commons-lang3-3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.2.4.jar,file:///home/jovyan/.ivy2/jars/com.google.guava_guava-24.1.1-jre.jar,file:///home/jovyan/.ivy2/jars/com.google.code.findbugs_jsr305-1.3.9.jar,file:///home/jovyan/.ivy2/jars/org.checkerframework_checker-compat-qual-2.0.0.jar,file:///home/jovyan/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.1.3.jar,file:///home/jovyan/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.14.jar'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.jars',\n",
       "  'file:///home/jovyan/.ivy2/jars/org.apache.hadoop_hadoop-azure-3.3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-storage-8.6.6.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpclient-4.5.13.jar,file:///home/jovyan/.ivy2/jars/org.apache.hadoop.thirdparty_hadoop-shaded-guava-1.1.1.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-ajax-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar,file:///home/jovyan/.ivy2/jars/org.wildfly.openssl_wildfly-openssl-1.0.7.Final.jar,file:///home/jovyan/.ivy2/jars/org.apache.httpcomponents_httpcore-4.4.13.jar,file:///home/jovyan/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar,file:///home/jovyan/.ivy2/jars/commons-codec_commons-codec-1.15.jar,file:///home/jovyan/.ivy2/jars/org.eclipse.jetty_jetty-util-9.4.43.v20210629.jar,file:///home/jovyan/.ivy2/jars/com.fasterxml.jackson.core_jackson-core-2.9.4.jar,file:///home/jovyan/.ivy2/jars/org.slf4j_slf4j-api-1.7.12.jar,file:///home/jovyan/.ivy2/jars/org.apache.commons_commons-lang3-3.4.jar,file:///home/jovyan/.ivy2/jars/com.microsoft.azure_azure-keyvault-core-1.2.4.jar,file:///home/jovyan/.ivy2/jars/com.google.guava_guava-24.1.1-jre.jar,file:///home/jovyan/.ivy2/jars/com.google.code.findbugs_jsr305-1.3.9.jar,file:///home/jovyan/.ivy2/jars/org.checkerframework_checker-compat-qual-2.0.0.jar,file:///home/jovyan/.ivy2/jars/com.google.errorprone_error_prone_annotations-2.1.3.jar,file:///home/jovyan/.ivy2/jars/com.google.j2objc_j2objc-annotations-1.1.jar,file:///home/jovyan/.ivy2/jars/org.codehaus.mojo_animal-sniffer-annotations-1.14.jar'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc._conf.getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.3 Importação dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3.1. Base \"airline delay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "BtlPQBMUev9f"
   },
   "outputs": [],
   "source": [
    "STORAGE_ACCOUNT = 'dlspadseastusprod'\n",
    "CONTAINER = 'big-data-comp-nuvem'\n",
    "FOLDER = 'airline-delay'\n",
    "TOKEN = 'lSuH4ZI9BhOFEhCF/7ZQbrpPBIhgtLcPDfXjJ8lMxQZjaADW4p6tcmiZGDX9u05o7FqSE2t9d2RD+ASt0YFG8g=='\n",
    "\n",
    "spark.conf.set(\"fs.azure.account.key.\" + STORAGE_ACCOUNT + \".blob.core.windows.net\", TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = red> \n",
    "    No snipet abaixo estamos importanto dados apenas para o arquivo do ano de 2011. Ajustar para importar dos demais anos\n",
    "    <font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "pfBLgWVPk1Xe",
    "outputId": "ea7abda6-e0df-4f07-fe30-6cef0b26e389"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>ACTUAL_ELAPSED_TIME</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4529</td>\n",
       "      <td>BOS</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1830</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4532</td>\n",
       "      <td>BNA</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1100</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4532</td>\n",
       "      <td>DCA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1400</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4537</td>\n",
       "      <td>RDU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1710</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4540</td>\n",
       "      <td>CMH</td>\n",
       "      <td>LGA</td>\n",
       "      <td>1340</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>...</td>\n",
       "      <td>105.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0 2011-01-01         MQ               4529    BOS  JFK          1830   \n",
       "1 2011-01-01         MQ               4532    BNA  DCA          1100   \n",
       "2 2011-01-01         MQ               4532    DCA  JFK          1400   \n",
       "3 2011-01-01         MQ               4537    RDU  JFK          1710   \n",
       "4 2011-01-01         MQ               4540    CMH  LGA          1340   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  CRS_ELAPSED_TIME  \\\n",
       "0    1823.0       -7.0      68.0      1931.0  ...              90.0   \n",
       "1    1052.0       -8.0      11.0      1103.0  ...              95.0   \n",
       "2    1358.0       -2.0       9.0      1407.0  ...              79.0   \n",
       "3    1706.0       -4.0      59.0      1805.0  ...             105.0   \n",
       "4    1340.0        0.0      14.0      1354.0  ...             105.0   \n",
       "\n",
       "   ACTUAL_ELAPSED_TIME  AIR_TIME  DISTANCE  CARRIER_DELAY  WEATHER_DELAY  \\\n",
       "0                146.0      48.0     187.0            0.0            0.0   \n",
       "1                 88.0      74.0     562.0            NaN            NaN   \n",
       "2                 73.0      60.0     213.0            NaN            NaN   \n",
       "3                159.0      85.0     426.0            0.0            0.0   \n",
       "4                 95.0      77.0     478.0            NaN            NaN   \n",
       "\n",
       "  NAS_DELAY  SECURITY_DELAY  LATE_AIRCRAFT_DELAY  Unnamed: 27  \n",
       "0      49.0             0.0                  0.0         None  \n",
       "1       NaN             NaN                  NaN         None  \n",
       "2       NaN             NaN                  NaN         None  \n",
       "3      50.0             0.0                  0.0         None  \n",
       "4       NaN             NaN                  NaN         None  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "config.set(\"fs.azure.account.key.\" + STORAGE_ACCOUNT + \".blob.core.windows.net\", TOKEN)\n",
    "\n",
    "df_airline_delay = spark.read.csv(\"wasbs://{}@{}.blob.core.windows.net/{}/2011.csv\".format(CONTAINER, STORAGE_ACCOUNT, FOLDER), header=True, inferSchema=True)\n",
    "\n",
    "df_airline_delay.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.3.2. Base \"weather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>tavg</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>December</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>50.4</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>67.4</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>September</td>\n",
       "      <td>79.4</td>\n",
       "      <td>6.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2018</td>\n",
       "      <td>August</td>\n",
       "      <td>79.5</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Year      Month  tavg   pcp\n",
       "0  Alabama  2018   December  49.0  9.95\n",
       "1  Alabama  2018   November  50.4  6.29\n",
       "2  Alabama  2018    October  67.4  2.69\n",
       "3  Alabama  2018  September  79.4  6.21\n",
       "4  Alabama  2018     August  79.5  5.03"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL do arquivo no GitHub\n",
    "url = \"https://github.com/adambry/Projeto_Final_BigData/raw/main/df_weather.csv\"\n",
    "\n",
    "df_weather = pd.read_csv(url)\n",
    "\n",
    "df_weather = spark.createDataFrame(df_weather)\n",
    "\n",
    "df_weather.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando ocorrência de duplicadas na base\n",
    "df_weather_duplicadas = df_weather.groupBy(\"State\", \"Year\",\"Month\", \"tavg\", \"pcp\").count().filter(col(\"count\") > 1)\n",
    "\n",
    "df_weather_duplicadas.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veriricamos que a importação dos dados via o WebScrapping duplicou cada valor na base. Portanto, removeremos as duplicadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5880"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = df_weather.dropDuplicates()\n",
    "\n",
    "df_weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrando dados do ano de 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State     49\n",
       "Year       1\n",
       "Month     12\n",
       "tavg     394\n",
       "pcp      391\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather = df_weather.filter(col(\"Year\") == 2011)\n",
    "\n",
    "df_weather.toPandas().nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. Base \"airports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>iata_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>FL</td>\n",
       "      <td>OCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>PQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>US</td>\n",
       "      <td>CO</td>\n",
       "      <td>CSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>TX</td>\n",
       "      <td>JCY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small_airport</td>\n",
       "      <td>Nunapitchuk Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>NUP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type                     name iso_country iso_region iata_code\n",
       "0  small_airport  Ocean Reef Club Airport          US         FL       OCA\n",
       "1  small_airport    Pilot Station Airport          US         AK       PQS\n",
       "2  small_airport    Crested Butte Airpark          US         CO       CSE\n",
       "3  small_airport        LBJ Ranch Airport          US         TX       JCY\n",
       "4  small_airport      Nunapitchuk Airport          US         AK       NUP"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/adambry/Projeto_Final_BigData/main/Aeroportos_US.csv'\n",
    "\n",
    "# Especifique as colunas de interesse\n",
    "df_airports_region = pd.read_csv(url, delimiter=';')\n",
    "\n",
    "df_airports_region = spark.createDataFrame(df_airports_region)\n",
    "\n",
    "df_airports_region.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TRATAMENTO NOS DADOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Limpeza Aeroportos fora dos EUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estudo da base para verificar se os estados registrados na coluna STATE na base df_airports_region estão corretos\n",
    "df_airports_region.select(\"iso_region\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabemos que os Estados Unidos possuem 50 estados. Poranto, precisamos vamos identificar os excedentes e retirá-los da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|iso_region|\n",
      "+----------+\n",
      "|        DC|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# identificando Estados Excedentes\n",
    "\n",
    "# Lista de estados dos EUA (https://pt.wikipedia.org/wiki/Estados_dos_Estados_Unidos)\n",
    "us_states = ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY']\n",
    "\n",
    "# Filtra os estados excedentes\n",
    "excess_states = df_airports_region.select(\"iso_region\").distinct().filter(~col(\"iso_region\").isin(us_states))\n",
    "\n",
    "# Exibe os estados excedentes\n",
    "excess_states.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "verificando quais aeroportos estão nos Estados não identificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------------------------------+-----------+----------+---------+\n",
      "|type         |name                                     |iso_country|iso_region|iata_code|\n",
      "+-------------+-----------------------------------------+-----------+----------+---------+\n",
      "|large_airport|Ronald Reagan Washington National Airport|US         |DC        |DCA      |\n",
      "+-------------+-----------------------------------------+-----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtra os aeroportos com base nos estados excedentes\n",
    "df_excess_airports = df_airports_region.filter(col(\"iso_region\").isin([row.iso_region for row in excess_states.collect()]))\n",
    "\n",
    "# Exibe os aeroportos nos estados excedentes\n",
    "df_excess_airports.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de consultas na internet, verificamos que este aeroporto fica em Washginton. Portanto, a iso_region deve ser alterado para WA, sigla do Estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substitui o valor \"DC\" por \"WA\" na coluna \"iso_region\"\n",
    "df_airports_region = df_airports_region.withColumn(\"iso_region\", when(col(\"iso_region\") == \"DC\", \"WA\").otherwise(col(\"iso_region\")))\n",
    "\n",
    "# Exibe os aeroportos após a substituição\n",
    "df_airports_region.select(\"iso_region\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Padronização das variáveis string (retirada de espaços e snakecase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l2b1lRnTt63",
    "tags": []
   },
   "source": [
    "## 2.3. Join nas tabelas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. airport_region e airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformação da sigla dos estados para o nome por extenso para corresponder aos valores da tabela df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-----------+----------+---------+---------------+\n",
      "|         type|                name|iso_country|iso_region|iata_code|STATE_FULL_NAME|\n",
      "+-------------+--------------------+-----------+----------+---------+---------------+\n",
      "|small_airport|Ocean Reef Club A...|         US|        FL|      OCA|        Florida|\n",
      "|small_airport|Pilot Station Air...|         US|        AK|      PQS|         Alaska|\n",
      "|small_airport|Crested Butte Air...|         US|        CO|      CSE|       Colorado|\n",
      "|small_airport|   LBJ Ranch Airport|         US|        TX|      JCY|          Texas|\n",
      "|small_airport| Nunapitchuk Airport|         US|        AK|      NUP|         Alaska|\n",
      "+-------------+--------------------+-----------+----------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "state_full_name = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# Criar a nova coluna com nomes de estados por extenso\n",
    "df_airports_region = df_airports_region.withColumn(\"STATE_FULL_NAME\", col(\"iso_region\").cast(\"string\")).replace(state_full_name, subset=\"STATE_FULL_NAME\")\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "df_airports_region.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junção das tabelas weather e airports region utilizando como chave a coluna com o nome dos Estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando se todos os valores corresponderam entre as duas tabelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Join nas tabelas df_airport_region e df_airline_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando colunas de ano e mês a partir da FL_DATE na tabela df_airline_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airline_delay = df_airline_delay.withColumn(\"Year\", year(\"FL_DATE\")).withColumn(\"Month\", date_format(col(\"FL_DATE\"), \"MMMM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>AIR_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>CARRIER_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4529</td>\n",
       "      <td>BOS</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1830</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4532</td>\n",
       "      <td>BNA</td>\n",
       "      <td>DCA</td>\n",
       "      <td>1100</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4532</td>\n",
       "      <td>DCA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1400</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4537</td>\n",
       "      <td>RDU</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1710</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>MQ</td>\n",
       "      <td>4540</td>\n",
       "      <td>CMH</td>\n",
       "      <td>LGA</td>\n",
       "      <td>1340</td>\n",
       "      <td>1340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1354.0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>January</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0 2011-01-01         MQ               4529    BOS  JFK          1830   \n",
       "1 2011-01-01         MQ               4532    BNA  DCA          1100   \n",
       "2 2011-01-01         MQ               4532    DCA  JFK          1400   \n",
       "3 2011-01-01         MQ               4537    RDU  JFK          1710   \n",
       "4 2011-01-01         MQ               4540    CMH  LGA          1340   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...  AIR_TIME  DISTANCE  \\\n",
       "0    1823.0       -7.0      68.0      1931.0  ...      48.0     187.0   \n",
       "1    1052.0       -8.0      11.0      1103.0  ...      74.0     562.0   \n",
       "2    1358.0       -2.0       9.0      1407.0  ...      60.0     213.0   \n",
       "3    1706.0       -4.0      59.0      1805.0  ...      85.0     426.0   \n",
       "4    1340.0        0.0      14.0      1354.0  ...      77.0     478.0   \n",
       "\n",
       "   CARRIER_DELAY  WEATHER_DELAY  NAS_DELAY  SECURITY_DELAY  \\\n",
       "0            0.0            0.0       49.0             0.0   \n",
       "1            NaN            NaN        NaN             NaN   \n",
       "2            NaN            NaN        NaN             NaN   \n",
       "3            0.0            0.0       50.0             0.0   \n",
       "4            NaN            NaN        NaN             NaN   \n",
       "\n",
       "  LATE_AIRCRAFT_DELAY  Unnamed: 27  Year    Month  \n",
       "0                 0.0         None  2011  January  \n",
       "1                 NaN         None  2011  January  \n",
       "2                 NaN         None  2011  January  \n",
       "3                 0.0         None  2011  January  \n",
       "4                 NaN         None  2011  January  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline_delay.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6038444"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airline_delay_airports = df_airline_delay.join(df_airports_region, df_airline_delay.ORIGIN == df_airports_region.iata_code, \"inner\")\n",
    "\n",
    "df_airline_delay_airports.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Join nas tabelas df_airline_delay_airports e df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_erro = df_airline_delay_airports.join(df_weather, (df_airline_delay_airports.STATE_FULL_NAME == df_weather.State) & (df_airline_delay_airports.Year == df_weather.Year) & (df_airline_delay_airports.Month == df_weather.Month), \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>OP_CARRIER_FL_NUM</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>TAXI_OUT</th>\n",
       "      <th>WHEELS_OFF</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>STATE_FULL_NAME</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>tavg</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>62</td>\n",
       "      <td>LIH</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1426</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lihue Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>HI</td>\n",
       "      <td>LIH</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>64</td>\n",
       "      <td>LIH</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2255</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lihue Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>HI</td>\n",
       "      <td>LIH</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>66</td>\n",
       "      <td>LIH</td>\n",
       "      <td>LAX</td>\n",
       "      <td>1356</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lihue Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>HI</td>\n",
       "      <td>LIH</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>68</td>\n",
       "      <td>LIH</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2203</td>\n",
       "      <td>2158.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lihue Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>HI</td>\n",
       "      <td>LIH</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>454</td>\n",
       "      <td>LIH</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2120</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lihue Airport</td>\n",
       "      <td>US</td>\n",
       "      <td>HI</td>\n",
       "      <td>LIH</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FL_DATE OP_CARRIER  OP_CARRIER_FL_NUM ORIGIN DEST  CRS_DEP_TIME  \\\n",
       "0 2011-01-01         UA                 62    LIH  SFO          1426   \n",
       "1 2011-01-01         UA                 64    LIH  SFO          2255   \n",
       "2 2011-01-01         UA                 66    LIH  LAX          1356   \n",
       "3 2011-01-01         UA                 68    LIH  LAX          2203   \n",
       "4 2011-01-01         UA                454    LIH  DEN          2120   \n",
       "\n",
       "   DEP_TIME  DEP_DELAY  TAXI_OUT  WHEELS_OFF  ...           name  iso_country  \\\n",
       "0    1420.0       -6.0       8.0      1428.0  ...  Lihue Airport           US   \n",
       "1    2251.0       -4.0      11.0      2302.0  ...  Lihue Airport           US   \n",
       "2    1352.0       -4.0      10.0      1402.0  ...  Lihue Airport           US   \n",
       "3    2158.0       -5.0      12.0      2210.0  ...  Lihue Airport           US   \n",
       "4    2110.0      -10.0      11.0      2121.0  ...  Lihue Airport           US   \n",
       "\n",
       "   iso_region  iata_code  STATE_FULL_NAME  State Year  Month  tavg  pcp  \n",
       "0          HI        LIH           Hawaii   None  NaN   None   NaN  NaN  \n",
       "1          HI        LIH           Hawaii   None  NaN   None   NaN  NaN  \n",
       "2          HI        LIH           Hawaii   None  NaN   None   NaN  NaN  \n",
       "3          HI        LIH           Hawaii   None  NaN   None   NaN  NaN  \n",
       "4          HI        LIH           Hawaii   None  NaN   None   NaN  NaN  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtra para incluir apenas as linhas onde a tabela da esquerda não teve correspondência\n",
    "unmatched_rows = df_erro.filter(col(\"State\").isNull())\n",
    "\n",
    "# Exibe as linhas não correspondidas\n",
    "unmatched_rows.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101304"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_rows.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|STATE_FULL_NAME|\n",
      "+---------------+\n",
      "|           Utah|\n",
      "|         Hawaii|\n",
      "|      Minnesota|\n",
      "|           Ohio|\n",
      "|         Oregon|\n",
      "|       Arkansas|\n",
      "|          Texas|\n",
      "|   North Dakota|\n",
      "|   Pennsylvania|\n",
      "|    Connecticut|\n",
      "|       Nebraska|\n",
      "|        Vermont|\n",
      "|         Nevada|\n",
      "|     Washington|\n",
      "|       Illinois|\n",
      "|       Oklahoma|\n",
      "|         Alaska|\n",
      "|     New Mexico|\n",
      "|  West Virginia|\n",
      "|       Missouri|\n",
      "+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_erro.select(\"STATE_FULL_NAME\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando dataframe que será utilizado no pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+----+-------+--------------+--------------------+-----------+----------+---------+---------------+---------+----+-------+----+----+\n",
      "|            FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|Year|  Month|          type|                name|iso_country|iso_region|iata_code|STATE_FULL_NAME|    State|Year|  Month|tavg| pcp|\n",
      "+-------------------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+----+-------+--------------+--------------------+-----------+----------+---------+---------------+---------+----+-------+----+----+\n",
      "|2011-01-31 00:00:00|        EV|             5629|   BGM| DTW|         600|   554.0|     -6.0|    40.0|     634.0|    754.0|    8.0|         750|   802.0|     12.0|      0.0|             null|     0.0|           110.0|              128.0|    80.0|   378.0|         null|         null|     null|          null|               null|       null|2011|January|medium_airport|Greater Binghamto...|         US|        NY|      BGM|       New York| New York|2011|January|18.6|2.01|\n",
      "|2011-01-01 00:00:00|        UA|              239|   MSY| LAX|         700|   708.0|      8.0|     8.0|     716.0|    919.0|    9.0|         924|   928.0|      4.0|      0.0|             null|     0.0|           264.0|              260.0|   243.0|  1671.0|         null|         null|     null|          null|               null|       null|2011|January| large_airport|Louis Armstrong N...|         US|        LA|      MSY|      Louisiana|Louisiana|2011|January|46.9|4.75|\n",
      "|2011-01-01 00:00:00|        UA|              263|   MSY| LAX|        1927|  1929.0|      2.0|     9.0|    1938.0|   2137.0|    9.0|        2152|  2146.0|     -6.0|      0.0|             null|     0.0|           265.0|              257.0|   239.0|  1671.0|         null|         null|     null|          null|               null|       null|2011|January| large_airport|Louis Armstrong N...|         US|        LA|      MSY|      Louisiana|Louisiana|2011|January|46.9|4.75|\n",
      "|2011-01-01 00:00:00|        UA|              368|   MSY| IAD|         755|   804.0|      9.0|     9.0|     813.0|   1115.0|    8.0|        1118|  1123.0|      5.0|      0.0|             null|     0.0|           143.0|              139.0|   122.0|   954.0|         null|         null|     null|          null|               null|       null|2011|January| large_airport|Louis Armstrong N...|         US|        LA|      MSY|      Louisiana|Louisiana|2011|January|46.9|4.75|\n",
      "|2011-01-01 00:00:00|        UA|              380|   MSY| IAD|        1739|  1729.0|    -10.0|    10.0|    1739.0|   2036.0|    6.0|        2109|  2042.0|    -27.0|      0.0|             null|     0.0|           150.0|              133.0|   117.0|   954.0|         null|         null|     null|          null|               null|       null|2011|January| large_airport|Louis Armstrong N...|         US|        LA|      MSY|      Louisiana|Louisiana|2011|January|46.9|4.75|\n",
      "+-------------------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+----+-------+--------------+--------------------+-----------+----------+---------+---------------+---------+----+-------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_airline_delay_airports.join(df_weather, (df_airline_delay_airports.STATE_FULL_NAME == df_weather.State) & (df_airline_delay_airports.Year == df_weather.Year) & (df_airline_delay_airports.Month == df_weather.Month), \"inner\")\n",
    "\n",
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = red> Retirar colunas que não fazem sentido do DF <font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('WEATHER_DELAY_BIN', when(col('WEATHER_DELAY') == 0, 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Criação de colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1.1 Cassificando atrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo variável com valor dos percentis 0.33 e 0.66 para posteriormente segmentar as distâncias.\n",
    "# documentação consultada: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.approxQuantile.html\n",
    "\n",
    "# percentis = df.stat.approxQuantile(\"DISTANCE\", [0.33, 0.66], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Foi necessário utilizar o recurso de format ao invés de utilizar diretamente a referência do objetos da variável percentis no corpo da expressão porque, de outra forma, o \\nPySpark interpretou percentis[0] e percentis[1] como literais de string, e não como valores da lista criada na variável percentis'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando coluna no dataframe para classificação das distâncias a partir dos percentis calculados\n",
    "# Foi utilizado o percentis[0] para acessar os valor do percentil 0.33 e percentis[1] para acessar o valor de percentis 0.66.\n",
    "''' Foi necessário utilizar o recurso de format ao invés de utilizar diretamente a referência do objetos da variável percentis no corpo da expressão porque, de outra forma, o \n",
    "PySpark interpretou percentis[0] e percentis[1] como literais de string, e não como valores da lista criada na variável percentis'''\n",
    "\n",
    "# df_classificacao_distancias = df.withColumn(\n",
    "#     'CLASSIFICACAO_DISTANCIAS',\n",
    "#     expr(\n",
    "#         \"CASE WHEN distance <= {} THEN 'proximos'\"\n",
    "#         \" WHEN distance <= {} THEN 'medio'\"\n",
    "#         \" ELSE 'distantes' END\".format(percentis[0], percentis[1])\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# df_classificacao_distancias.show(10)\n",
    "\n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Análise Descritiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Análise Univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Variáveis numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> criar aqui gráficos para visualizarmos a dispersão dos dados em boxplot para as colunas numéricas pertinentes <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Variáveis categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> criar aqui gráficos para visualizarmos a frequência das categorias para cada variável <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Criação de hipóteses\n",
    "\n",
    "<font color = red> criar aqui hipóteses subjetivas (de acordo com nossa interpretação subjetivas sobre os dados) de como as variáveis se comportam frente à variável resposta <font>\n",
    "    \n",
    "    Por exemplo: \n",
    "    1. Vôos entre aeroportos mais distantes tendem a ter mais atrasos por 'weather'\n",
    "    2. O número de vôos cancelados por motivos de 'weather' é maior em meses que possuem maior precipitação\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Análise Bivariada\n",
    "\n",
    "<font color=red> criar gráficos buscando responder as hipóteses criadas \n",
    "    <font>\n",
    "\n",
    "Isso é útil para criarmos uma intuição sobre a importância das variáveis nos modelos e obter maior autonomia para manipulação, evitando que nos tornemos totalmente dependente somente de algorítmos para seleção de variáveis, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Calculando % atraso em cada faixa\n",
    "\n",
    "<font color = red> necessita ajuste para pegar apenas vôos cancelados por motivo de 'weather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencia_absoluta = df_classificacao_distancias.groupBy(\"CLASSIFICACAO_DISTANCIAS\").count()\n",
    "# total_atrasos = df_classificacao_distancias.count()\n",
    "\n",
    "# frequencia_absoluta.show()\n",
    "# total_atrasos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# porcentagem_atrasos_por_classificacao_distancia = frequencia_absoluta.withColumn(\n",
    "#     \"PORCENTAGEM\",\n",
    "#     expr(\"count / {} * 100\".format(total_atrasos))\n",
    "# )\n",
    "\n",
    "# porcentagem_atrasos_por_classificacao_distancia.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2. Número de vôos diários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotando gráfico com o número de vôos diários\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# ax = sns.lineplot(data=df_BOS_agrupado_data_pandas, x='FL_DATE', y='count')\n",
    "# ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha='right')\n",
    "# ax.set(title='Número Diário de Voos',\n",
    "#        xlabel='Data',\n",
    "#        ylabel='Número de Voos')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2. Análise Multivariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color= red> plotar aqui gráfico de correlação <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modelagem de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ORIGIN', 'DEST', 'State', 'tavg', 'pcp', 'WEATHER_DELAY_BIN']\n",
    "df_ml = df.select(*cols)\n",
    "\n",
    "df_ml_sample = df_ml.sample(fraction=0.1, seed=3)\n",
    "\n",
    "cat_columns = ['ORIGIN', 'DEST', 'State']\n",
    "num_columns = ['tavg', 'pcp']\n",
    "\n",
    "index_output = [x+\"Index\" for x in cat_columns]\n",
    "ohe_output = [x+\"OHE\" for x in cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCols=cat_columns,\n",
    "                             outputCols=index_output,\n",
    "                             handleInvalid=\"skip\")\n",
    "\n",
    "oheEncoder = OneHotEncoder(inputCols=index_output,\n",
    "                          outputCols=ohe_output)\n",
    "\n",
    "# Montar os recursos em um vetor\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs,\n",
    "                     outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "(train_data, test_data) = df_ml_sample.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Criar instâncias dos modelos de Regressão Logística e Floresta Aleatória\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:0.9999999457990196\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='WEATHER_DELAY_BIN')\n",
    "pipeline_lr = Pipeline(stages=[stringIndexer, oheEncoder, assembler, lr])\n",
    "\n",
    "model_lr = pipeline_lr.fit(train_data)\n",
    "\n",
    "predictions_lr = model_lr.transform(test_data)\n",
    "\n",
    "evaluator_lr = BinaryClassificationEvaluator(labelCol='WEATHER_DELAY_BIN')\n",
    "\n",
    "evaluation_lr = evaluator_lr.evaluate(predictions_lr)\n",
    "\n",
    "print(f'AUC:{evaluation_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Floresta Aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:0.08993337109305\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol='features', labelCol='WEATHER_DELAY_BIN')\n",
    "pipeline_rf = Pipeline(stages=[stringIndexer, oheEncoder, assembler, rf])\n",
    "\n",
    "model_rf = pipeline_rf.fit(train_data)\n",
    "\n",
    "predictions_rf = model_rf.transform(test_data)\n",
    "\n",
    "evaluator_rf = RegressionEvaluator(labelCol=\"WEATHER_DELAY_BIN\", predictionCol=\"prediction\")\n",
    "\n",
    "evaluation_rf = evaluator_rf.evaluate(predictions_rf)\n",
    "\n",
    "print(f'RMSE:{evaluation_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Floresta aleatória com otimização de hiperparâmetros e validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "            .addGrid(rf.numTrees, [10, 100])\n",
    "            .build)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'method' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m CrossValidator(\n\u001b[1;32m      2\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline_rf,\n\u001b[1;32m      3\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mevaluator_rf,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m cvModel \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/ml/tuning.py:827\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    825\u001b[0m est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)\n\u001b[1;32m    826\u001b[0m epm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimatorParamMaps)\n\u001b[0;32m--> 827\u001b[0m numModels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    828\u001b[0m eva \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator)\n\u001b[1;32m    829\u001b[0m nFolds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetOrDefault(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumFolds)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'method' has no len()"
     ]
    }
   ],
   "source": [
    "cv = CrossValidator(\n",
    "    estimator=pipeline_rf,\n",
    "    evaluator=evaluator_rf,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    numFolds=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "cvModel = cv.fit(train_data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
